import pandas as pd
import json
import os
from datetime import datetime

def export_to_json(input_path="data/candidates_c.csv", output_path="data/data.json"):
    print("ğŸ“ Module D: Generating Operation Report...")
    
    # --- [1. ì „ì¥ ìƒí™©íŒ (ë‹¨ê³„ë³„ ë¡œê·¸ ìˆ˜ì§‘)] ---
    logs = []
    stats = {"universe": 0, "s1_filtered": 0, "s2_checked": 0, "final_ready": 0}

    # Step A: Universe í™•ì¸
    if os.path.exists("data/universe.csv"):
        try:
            uni_df = pd.read_csv("data/universe.csv")
            stats['universe'] = len(uni_df)
            logs.append(f"âœ… [Step 1] Universe Secured: {len(uni_df):,} tickers found.")
        except:
            logs.append("âš ï¸ [Step 1] Universe file exists but is unreadable.")
    else:
        logs.append("âŒ [Step 1] Universe file NOT found. (Pipeline broken?)")

    # Step B: Technical Scan í™•ì¸
    if os.path.exists("data/candidates_b.csv"):
        try:
            b_df = pd.read_csv("data/candidates_b.csv")
            stats['s1_filtered'] = len(b_df)
            if len(b_df) > 0:
                logs.append(f"âœ… [Step 2] Technical Scan: {len(b_df)} candidates survived the drop.")
            else:
                logs.append("âš ï¸ [Step 2] No candidates met the technical criteria.")
        except:
            logs.append("âš ï¸ [Step 2] Scanner file error.")
    else:
        logs.append("â­ï¸ [Step 2] Scanner output missing (Skipped or Failed).")

    # Step C: News Analysis í™•ì¸
    candidates = []
    if os.path.exists(input_path):
        try:
            df = pd.read_csv(input_path)
            stats['s2_checked'] = len(df)
            
            if not df.empty:
                logs.append(f"âœ… [Step 3] News Filter: {len(df)} candidates passed risk check.")
                
                # ë°ì´í„° ë§¤í•‘ ì‹œì‘
                for _, row in df.iterrows():
                    rec_rate = row.get('recovery_rate', 0) / 100.0
                    tag = "READY" if rec_rate >= 0.10 else "WATCH"
                    if tag == "READY": stats['final_ready'] += 1
                    
                    candidate = {
                        "ticker": str(row['ticker']),
                        "price": float(row['price']),
                        "metrics": {
                            "drop_rate": row.get('drop_rate', 0),
                            "rec_rate": rec_rate
                        },
                        "evidence": {
                            "s4_tag": tag
                        },
                        "context": str(row.get('news_top', 'No News Data'))
                    }
                    candidates.append(candidate)
            else:
                logs.append("âš ï¸ [Step 3] Candidates list is empty after news filter.")
        except Exception as e:
            logs.append(f"âŒ [Step 3] Error processing final CSV: {str(e)}")
    else:
        logs.append("âŒ [Step 3] Final candidate file not found.")

    logs.append("ğŸ [System] Report generation complete.")

    # --- [2. ìµœì¢… JSON íŒ¨í‚¤ì§•] ---
    data = {
        "metadata": {
            "generated_at": datetime.now().strftime("%Y-%m-%d %H:%M:%S KST"),
            "pipeline_stats": stats,
            "system_logs": logs  # ëŒ€ì‹œë³´ë“œì— ë¿Œë¦´ ë¡œê·¸ ë¦¬ìŠ¤íŠ¸
        },
        "candidates": candidates
    }

    # íŒŒì¼ ì €ì¥
    try:
        with open(output_path, 'w', encoding='utf-8') as f:
            json.dump(data, f, indent=4, ensure_ascii=False)
        print(f"âœ… Module D: JSON generated successfully at {output_path}")
        return True
    except Exception as e:
        print(f"âŒ Module D: Failed to save JSON - {e}")
        return False
